{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cbecc3f",
   "metadata": {},
   "source": [
    "# Pruebas gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7d89284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9afe5db",
   "metadata": {},
   "source": [
    "## Calidad de generación del texto: BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d3b255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulmartinez/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c58ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_bleu(df):\n",
    "    predictions = df[\"output\"]\n",
    "    references = df[\"input\"]\n",
    "    bleu = evaluate.load (\"bleu\")\n",
    "    results = bleu.compute (predictions = predictions, references = references)\n",
    "    print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6af25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma sin rol 1\n",
      "{'bleu': 2.5562811827773874e-07, 'precisions': [0.7607627572116554, 0.26030283726172393, 0.10263118921854174, 0.05803948873526633], 'brevity_penalty': 1.3793543596593262e-06, 'length_ratio': 0.06899456622062017, 'translation_length': 20557, 'reference_length': 297951}\n",
      "Gemma con rol 1\n",
      "{'bleu': 1.567980944699892e-07, 'precisions': [0.7672171555336456, 0.2557238639185498, 0.0955716787590693, 0.05142425006301991], 'brevity_penalty': 8.898034684187848e-07, 'length_ratio': 0.06696907570460316, 'translation_length': 20285, 'reference_length': 302901}\n",
      "Gemma sin rol 0.5\n",
      "{'bleu': 2.631053367949994e-07, 'precisions': [0.7497828814049986, 0.24305015552099535, 0.09125624204445315, 0.04961530873939633], 'brevity_penalty': 1.5523949872243844e-06, 'length_ratio': 0.06956177358021956, 'translation_length': 20726, 'reference_length': 297951}\n",
      "Gemma con rol 0.5\n",
      "{'bleu': 1.3917434414003416e-07, 'precisions': [0.7550899093475999, 0.2517342915606129, 0.09076280987579827, 0.04635962912296702], 'brevity_penalty': 8.275837422342733e-07, 'length_ratio': 0.06664553765091565, 'translation_length': 20187, 'reference_length': 302901}\n",
      "Gemma sin rol 0.1\n",
      "{'bleu': 2.496596887105965e-07, 'precisions': [0.756826353124089, 0.25078308535630384, 0.09653880287940045, 0.05458970792767733], 'brevity_penalty': 1.403852995218568e-06, 'length_ratio': 0.06907847263476209, 'translation_length': 20582, 'reference_length': 297951}\n",
      "Gemma con rol 0.1\n",
      "{'bleu': 1.5168168675076225e-07, 'precisions': [0.7617123996255973, 0.2490446175988883, 0.09010450522526127, 0.04740792987052245], 'brevity_penalty': 8.990145667363073e-07, 'length_ratio': 0.06701529542655851, 'translation_length': 20299, 'reference_length': 302901}\n"
     ]
    }
   ],
   "source": [
    "df_gemma_sin_rol_1 = pd.read_csv(\"./analysis/gemma_sin_rol_1.csv\")\n",
    "df_gemma_con_rol_1 = pd.read_csv(\"./analysis/gemma_con_rol_1.csv\")\n",
    "df_gemma_sin_rol_0_5 = pd.read_csv(\"./analysis/gemma_sin_rol_0_5.csv\")\n",
    "df_gemma_con_rol_0_5 = pd.read_csv(\"./analysis/gemma_con_rol_0_5.csv\")\n",
    "df_gemma_sin_rol_0_1 = pd.read_csv(\"./analysis/gemma_sin_rol_0_1.csv\")\n",
    "df_gemma_con_rol_0_1 = pd.read_csv(\"./analysis/gemma_con_rol_0_1.csv\")\n",
    "\n",
    "print(\"Gemma sin rol 1\")\n",
    "calcular_bleu(df_gemma_sin_rol_1)\n",
    "print(\"Gemma con rol 1\")\n",
    "calcular_bleu(df_gemma_con_rol_1)\n",
    "print(\"Gemma sin rol 0.5\")\n",
    "calcular_bleu(df_gemma_sin_rol_0_5)\n",
    "print(\"Gemma con rol 0.5\")\n",
    "calcular_bleu(df_gemma_con_rol_0_5)\n",
    "print(\"Gemma sin rol 0.1\")\n",
    "calcular_bleu(df_gemma_sin_rol_0_1)\n",
    "print(\"Gemma con rol 0.1\")\n",
    "calcular_bleu(df_gemma_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29088aaf",
   "metadata": {},
   "source": [
    "## Comparación entre pruebas con rol y sin rol a diferentes temperaturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86df9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e6e80",
   "metadata": {},
   "source": [
    "### Bert por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c19bcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Bert por defecto\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41e25b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_bertscore_defecto(df_sin_rol, df_con_rol):\n",
    "    predictions = df_sin_rol[\"output\"]\n",
    "    references = df_con_rol[\"output\"]\n",
    "    results = bertscore.compute(predictions=predictions, references=references, lang=\"en\", model_type=\"distilbert-base-uncased\")\n",
    "    print(\"Precision:\", sum(results[\"precision\"]) / len(results[\"precision\"]))\n",
    "    print(\"Recall:\", sum(results[\"recall\"]) / len(results[\"recall\"]))\n",
    "    print(\"F1:\", sum(results[\"f1\"]) / len(results[\"f1\"]))\n",
    "    df = pd.DataFrame({\n",
    "    \"precision\": [np.mean(results[\"precision\"])],\n",
    "    \"recall\": [np.mean(results[\"recall\"])],\n",
    "    \"f1\": [np.mean(results[\"f1\"])]\n",
    "})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76ad2634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore por defecto a temperatura 1\n",
      "Precision: 0.9005568917592367\n",
      "Recall: 0.9007785137494405\n",
      "F1: 0.9005949890613556\n",
      "BertScore por defecto a temperatura 0.5\n",
      "Precision: 0.8772079618771871\n",
      "Recall: 0.8757964762051901\n",
      "F1: 0.876428058942159\n",
      "BertScore por defecto a temperatura 0.1\n",
      "Precision: 0.8983016264438629\n",
      "Recall: 0.8984694230556488\n",
      "F1: 0.8983149083455404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898302</td>\n",
       "      <td>0.898469</td>\n",
       "      <td>0.898315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        f1\n",
       "0   0.898302  0.898469  0.898315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"BertScore por defecto a temperatura 1\")\n",
    "calcular_bertscore_defecto(df_gemma_sin_rol_1, df_gemma_con_rol_1)\n",
    "print (\"BertScore por defecto a temperatura 0.5\")\n",
    "calcular_bertscore_defecto(df_gemma_sin_rol_0_5, df_gemma_con_rol_0_5)\n",
    "print (\"BertScore por defecto a temperatura 0.1\")\n",
    "calcular_bertscore_defecto(df_gemma_sin_rol_0_1, df_gemma_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95853a9c",
   "metadata": {},
   "source": [
    "### Bert utilizando modelo Bio_ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd93b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3c234ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_bertscore_bioclinical(df_sin_rol, df_con_rol):\n",
    "    predictions = df_sin_rol[\"output\"].astype(str).tolist()\n",
    "    references = df_con_rol[\"output\"].astype(str).tolist()\n",
    "\n",
    "    P, R, F1 = score(predictions, references, lang=\"en\", num_layers=12, idf=False, model_type=\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "    print(f\"Precission: {sum(P) / len(P)}\")\n",
    "    print(f\"Recall: {sum(R) / len(R)}\")\n",
    "    print(f\"F1: {sum(F1) / len(F1)}\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"precision\": [sum(P) / len(P)],\n",
    "        \"recall\": [sum(R) / len(R)],\n",
    "        \"f1\": [sum(F1) / len(F1)]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d02c339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore con modelo Bio_ClinicalBERT a temperatura 1\n",
      "Precission: 0.872083306312561\n",
      "Recall: 0.8703686594963074\n",
      "F1: 0.8710890412330627\n",
      "BertScore con modelo Bio_ClinicalBERT a temperatura 0.5\n",
      "Precission: 0.838509738445282\n",
      "Recall: 0.837006688117981\n",
      "F1: 0.8376386165618896\n",
      "BertScore con modelo Bio_ClinicalBERT a temperatura 0.1\n",
      "Precission: 0.8701820969581604\n",
      "Recall: 0.8672230839729309\n",
      "F1: 0.8686009645462036\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(0.8702)</td>\n",
       "      <td>tensor(0.8672)</td>\n",
       "      <td>tensor(0.8686)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision          recall              f1\n",
       "0  tensor(0.8702)  tensor(0.8672)  tensor(0.8686)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"BertScore con modelo Bio_ClinicalBERT a temperatura 1\")\n",
    "calcular_bertscore_bioclinical(df_gemma_sin_rol_1, df_gemma_con_rol_1)\n",
    "print (\"BertScore con modelo Bio_ClinicalBERT a temperatura 0.5\")\n",
    "calcular_bertscore_bioclinical(df_gemma_sin_rol_0_5, df_gemma_con_rol_0_5)\n",
    "print (\"BertScore con modelo Bio_ClinicalBERT a temperatura 0.1\")\n",
    "calcular_bertscore_bioclinical(df_gemma_sin_rol_0_1, df_gemma_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392e93d",
   "metadata": {},
   "source": [
    "## Medidas de readabilidad y comprensión del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install https://github.com/andreasvc/readability/tarball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66bd2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from textblob import TextBlob\n",
    "import readability\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7424fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompt(prompt_list,max_rows=5):\n",
    "    # Correctness (basic grammar check with spaCy)\n",
    "\n",
    "    flesh_scores = []\n",
    "    smog_scores = []\n",
    "    dale_scores = []\n",
    "    sentiment_polarity_scores = []\n",
    "    sentiment_subjectivity_scores = []\n",
    "    lexical_diversity_scores = []\n",
    "    lexical_richness_scores = []\n",
    "\n",
    "    for prompt_element in prompt_list[:max_rows]:\n",
    "        prompt = prompt_element['text']\n",
    "\n",
    "        # Clarity (readability score using Readability)\n",
    "        results_r = readability.getmeasures(prompt, lang='en')\n",
    "        flesch_reading_ease = results_r['readability grades']['FleschReadingEase']\n",
    "        flesh_scores.append(flesch_reading_ease)\n",
    "\n",
    "        flesch_reading_ease = results_r['readability grades']['FleschReadingEase']\n",
    "        smog_index = results_r['readability grades']['SMOGIndex']\n",
    "        smog_scores.append(smog_index)\n",
    "\n",
    "\n",
    "        dale_chall_score = results_r['readability grades']['DaleChallIndex']\n",
    "        dale_scores.append(dale_chall_score)\n",
    "\n",
    "        # Engagement (sentiment analysis with TextBlob)\n",
    "        blob = TextBlob(prompt)\n",
    "        sentiment_polarity_scores.append(blob.sentiment.polarity)\n",
    "        sentiment_subjectivity_scores.append(blob.sentiment.subjectivity)\n",
    "\n",
    "        words = prompt.split()\n",
    "        unique_words = set(words)\n",
    "        lexical_diversity = len(unique_words) / len(words) if words else 0\n",
    "        lexical_diversity_scores.append(lexical_diversity)\n",
    "\n",
    "        # Lexical richness (frequency distribution of words)\n",
    "        fdist = FreqDist(words)\n",
    "        lexical_richness = sum(fdist.freq(word) for word in unique_words) / len(unique_words) if unique_words else 0\n",
    "        lexical_richness_scores.append(lexical_richness)\n",
    "\n",
    "    return flesh_scores, smog_scores, dale_scores, sentiment_polarity_scores, sentiment_subjectivity_scores,lexical_diversity_scores,lexical_richness_scores\n",
    "\n",
    "  #'], engagement_scores[\"sentiment_polarity\"], engagement_scores[\"sentiment_subjectivity\"], engagement_scores[\"lexical_diversity\"], engagement_scores[\"lexical_richness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f96f13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_comprension(df):\n",
    "    prompt_list = [{'text': output} for output in df['output']]\n",
    "    flesh_scores, smog_scores, dale_scores, sentiment_polarity_scores, sentiment_subjectivity_scores, lexical_diversity_scores, lexical_richness_scores = evaluate_prompt(prompt_list)\n",
    "\n",
    "    print(\"Flesch Reading Ease Scores:\", sum(flesh_scores) / len(flesh_scores))\n",
    "    print(\"SMOG Index Scores:\", sum(smog_scores) / len(smog_scores))\n",
    "    print(\"Dale-Chall Index Scores:\", sum(dale_scores) / len(dale_scores))\n",
    "    print(\"Sentiment Polarity Scores:\", sum(sentiment_polarity_scores) / len(sentiment_polarity_scores))\n",
    "    print(\"Sentiment Subjectivity Scores:\", sum(sentiment_subjectivity_scores) / len(sentiment_subjectivity_scores))\n",
    "    print(\"Lexical Diversity Scores:\", sum(lexical_diversity_scores) / len(lexical_diversity_scores))\n",
    "    print(\"Lexical Richness Scores:\", sum(lexical_richness_scores) / len(lexical_richness_scores))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"flesch_reading_ease\": [np.mean(flesh_scores)],\n",
    "        \"smog_index\": [np.mean(smog_scores)],\n",
    "        \"dale_chall_index\": [np.mean(dale_scores)],\n",
    "        \"sentiment_polarity\": [np.mean(sentiment_polarity_scores)],\n",
    "        \"sentiment_subjectivity\": [np.mean(sentiment_subjectivity_scores)],\n",
    "        \"lexical_diversity\": [np.mean(lexical_diversity_scores)],\n",
    "        \"lexical_richness\": [np.mean(lexical_richness_scores)]\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d8e5cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas de readabilty y comprensión para sin rol a 1\n",
      "Flesch Reading Ease Scores: 34.22234708982448\n",
      "SMOG Index Scores: 13.058184468534472\n",
      "Dale-Chall Index Scores: 7.898114446416173\n",
      "Sentiment Polarity Scores: 0.022286375661375663\n",
      "Sentiment Subjectivity Scores: 0.3416752645502646\n",
      "Lexical Diversity Scores: 0.7564128854920904\n",
      "Lexical Richness Scores: 0.014400490012946335\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para con rol a 1\n",
      "Flesch Reading Ease Scores: 31.6450007348268\n",
      "SMOG Index Scores: 15.185644137160375\n",
      "Dale-Chall Index Scores: 8.598488592455155\n",
      "Sentiment Polarity Scores: 0.0637936507936508\n",
      "Sentiment Subjectivity Scores: 0.5060899470899471\n",
      "Lexical Diversity Scores: 0.7376177487147453\n",
      "Lexical Richness Scores: 0.014315781683464559\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para sin rol a 0.5\n",
      "Flesch Reading Ease Scores: 35.348670973085504\n",
      "SMOG Index Scores: 13.076315167439983\n",
      "Dale-Chall Index Scores: 7.5471840464458255\n",
      "Sentiment Polarity Scores: 0.030793650793650797\n",
      "Sentiment Subjectivity Scores: 0.36292328042328037\n",
      "Lexical Diversity Scores: 0.72620617232633\n",
      "Lexical Richness Scores: 0.014374741200828156\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para con rol a 0.5\n",
      "Flesch Reading Ease Scores: 40.63598333649142\n",
      "SMOG Index Scores: 12.420231713864512\n",
      "Dale-Chall Index Scores: 7.817201616878313\n",
      "Sentiment Polarity Scores: 0.09137301587301587\n",
      "Sentiment Subjectivity Scores: 0.41159523809523807\n",
      "Lexical Diversity Scores: 0.7362099554267395\n",
      "Lexical Richness Scores: 0.014039925866012826\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para sin rol a 0.1\n",
      "Flesch Reading Ease Scores: 37.81010786390976\n",
      "SMOG Index Scores: 14.065440972729153\n",
      "Dale-Chall Index Scores: 7.411284830961693\n",
      "Sentiment Polarity Scores: 0.013903619528619533\n",
      "Sentiment Subjectivity Scores: 0.3090010221260221\n",
      "Lexical Diversity Scores: 0.6874263705778775\n",
      "Lexical Richness Scores: 0.015186997703788747\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para con rol a 0.1\n",
      "Flesch Reading Ease Scores: 34.11296010780642\n",
      "SMOG Index Scores: 13.563942790429792\n",
      "Dale-Chall Index Scores: 8.029515303898048\n",
      "Sentiment Polarity Scores: 0.05619588744588744\n",
      "Sentiment Subjectivity Scores: 0.3835191197691198\n",
      "Lexical Diversity Scores: 0.7302980110544375\n",
      "Lexical Richness Scores: 0.0148789538001566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>dale_chall_index</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>lexical_richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.11296</td>\n",
       "      <td>13.563943</td>\n",
       "      <td>8.029515</td>\n",
       "      <td>0.056196</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.730298</td>\n",
       "      <td>0.014879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flesch_reading_ease  smog_index  dale_chall_index  sentiment_polarity  \\\n",
       "0             34.11296   13.563943          8.029515            0.056196   \n",
       "\n",
       "   sentiment_subjectivity  lexical_diversity  lexical_richness  \n",
       "0                0.383519           0.730298          0.014879  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Metricas de readabilty y comprensión para sin rol a 1\")\n",
    "calcular_metricas_comprension(df_gemma_sin_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para con rol a 1\")\n",
    "calcular_metricas_comprension(df_gemma_con_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para sin rol a 0.5\")\n",
    "calcular_metricas_comprension(df_gemma_sin_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para con rol a 0.5\")\n",
    "calcular_metricas_comprension(df_gemma_con_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para sin rol a 0.1\")\n",
    "calcular_metricas_comprension(df_gemma_sin_rol_0_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para con rol a 0.1\")\n",
    "calcular_metricas_comprension(df_gemma_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d49669",
   "metadata": {},
   "source": [
    "## Calcular longitud media de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc1d400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular longitud media de los textos por palabras\n",
    "def calculate_average_word_count(text_list):\n",
    "    total_words = sum(len(text.split()) for text in text_list)\n",
    "    average_word_count = total_words / len(text_list)\n",
    "    return average_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fd94830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_longitud_texto_y_respuesta(df):\n",
    "    longitud_textos = calculate_average_word_count(df['input'])\n",
    "    longitud_respuestas = calculate_average_word_count(df['output'])\n",
    "\n",
    "    print(f\"Longitud de los textos: {longitud_textos}\")\n",
    "    print(f\"Longitud de las respuestas: {longitud_respuestas}\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"longitud_textos\": [longitud_textos],\n",
    "        \"longitud_respuestas\": [longitud_respuestas]\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb5214af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud textos y respuestas sin rol a 1\n",
      "Longitud de los textos: 1440.46\n",
      "Longitud de las respuestas: 95.02\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas con rol a 1\n",
      "Longitud de los textos: 1458.46\n",
      "Longitud de las respuestas: 94.96666666666667\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas sin rol a 0.5\n",
      "Longitud de los textos: 1440.46\n",
      "Longitud de las respuestas: 95.31333333333333\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas con rol a 0.5\n",
      "Longitud de los textos: 1458.46\n",
      "Longitud de las respuestas: 94.72\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas sin rol a 0.1\n",
      "Longitud de los textos: 1440.46\n",
      "Longitud de las respuestas: 95.18666666666667\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas con rol a 0.1\n",
      "Longitud de los textos: 1458.46\n",
      "Longitud de las respuestas: 94.60666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitud_textos</th>\n",
       "      <th>longitud_respuestas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1458.46</td>\n",
       "      <td>94.606667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitud_textos  longitud_respuestas\n",
       "0          1458.46            94.606667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Longitud textos y respuestas sin rol a 1\")\n",
    "calcular_longitud_texto_y_respuesta(df_gemma_sin_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas con rol a 1\")\n",
    "calcular_longitud_texto_y_respuesta(df_gemma_con_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas sin rol a 0.5\")\n",
    "calcular_longitud_texto_y_respuesta(df_gemma_sin_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas con rol a 0.5\")\n",
    "calcular_longitud_texto_y_respuesta(df_gemma_con_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas sin rol a 0.1\")\n",
    "calcular_longitud_texto_y_respuesta(df_gemma_sin_rol_0_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas con rol a 0.1\")\n",
    "calcular_longitud_texto_y_respuesta(df_gemma_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becfba10",
   "metadata": {},
   "source": [
    "# Pruebas llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b043c1",
   "metadata": {},
   "source": [
    "## Calidad de generación del texto: BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18107a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama sin rol 1\n",
      "{'bleu': 2.756384901940513e-07, 'precisions': [0.7622970680881996, 0.260678545277032, 0.10508974674207032, 0.061332672776814465], 'brevity_penalty': 1.4570331028759703e-06, 'length_ratio': 0.06925635423274297, 'translation_length': 20635, 'reference_length': 297951}\n",
      "Llama con rol 1\n",
      "{'bleu': 3.219687978006532e-07, 'precisions': [0.8143569393569393, 0.43202091664103354, 0.2692705104360405, 0.20207226908257836], 'brevity_penalty': 8.655855826818002e-07, 'length_ratio': 0.06684554720099574, 'translation_length': 19656, 'reference_length': 294051}\n",
      "Llama sin rol 0.5\n",
      "{'bleu': 5.7681761830072085e-08, 'precisions': [0.8277514691618646, 0.4618748920987512, 0.3053926975097231, 0.24231422380980266], 'brevity_penalty': 1.4064459583071183e-07, 'length_ratio': 0.059605306562467056, 'translation_length': 17527, 'reference_length': 294051}\n",
      "Llama con rol 0.5\n",
      "{'bleu': 3.645467783442035e-07, 'precisions': [0.83871459805766, 0.4749705385048932, 0.3132131977074405, 0.24384659416141957], 'brevity_penalty': 8.728585274267961e-07, 'length_ratio': 0.06688295567775658, 'translation_length': 19667, 'reference_length': 294051}\n",
      "Llama sin rol 0.1\n",
      "{'bleu': 7.468615026644859e-08, 'precisions': [0.8104764558372806, 0.42028659735880863, 0.2551431000283366, 0.19165475850242927], 'brevity_penalty': 2.0789437052386512e-07, 'length_ratio': 0.061026828679378746, 'translation_length': 17945, 'reference_length': 294051}\n",
      "Llama con rol 0.1\n",
      "{'bleu': 2.1195670924680322e-07, 'precisions': [0.7940825949531064, 0.3870698208783748, 0.22480130533185957, 0.1574088811077511], 'brevity_penalty': 6.5633627201479e-07, 'length_ratio': 0.06563147209157595, 'translation_length': 19299, 'reference_length': 294051}\n"
     ]
    }
   ],
   "source": [
    "df_llama_sin_rol_1 = pd.read_csv(\"./analysis/llama_sin_rol_1.csv\")\n",
    "df_llama_con_rol_1 = pd.read_csv(\"./analysis/llama_con_rol_1.csv\")\n",
    "df_llama_sin_rol_0_5 = pd.read_csv(\"./analysis/llama_sin_rol_0_5.csv\")\n",
    "df_llama_con_rol_0_5 = pd.read_csv(\"./analysis/llama_con_rol_0_5.csv\")\n",
    "df_llama_sin_rol_0_1 = pd.read_csv(\"./analysis/llama_sin_rol_0_1.csv\")\n",
    "df_llama_con_rol_0_1 = pd.read_csv(\"./analysis/llama_con_rol_0_1.csv\")\n",
    "\n",
    "\n",
    "print(\"Llama sin rol 1\")\n",
    "calcular_bleu(df_llama_sin_rol_1)\n",
    "print(\"Llama con rol 1\")\n",
    "calcular_bleu(df_llama_con_rol_1)\n",
    "print(\"Llama sin rol 0.5\")\n",
    "calcular_bleu(df_llama_sin_rol_0_5)\n",
    "print(\"Llama con rol 0.5\")\n",
    "calcular_bleu(df_llama_con_rol_0_5)\n",
    "print(\"Llama sin rol 0.1\")\n",
    "calcular_bleu(df_llama_sin_rol_0_1)\n",
    "print(\"Llama con rol 0.1\")\n",
    "calcular_bleu(df_llama_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a132e38",
   "metadata": {},
   "source": [
    "## Comparación entre pruebas con rol y sin rol a diferentes temperaturas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3115562",
   "metadata": {},
   "source": [
    "### Bert por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0daff33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore por defecto a temperatura 1\n",
      "Precision: 0.8054464050134023\n",
      "Recall: 0.8010353072484334\n",
      "F1: 0.8030827442804972\n",
      "BertScore por defecto a temperatura 0.5\n",
      "Precision: 0.7990198000272115\n",
      "Recall: 0.8010387722651163\n",
      "F1: 0.7997263622283936\n",
      "BertScore por defecto a temperatura 0.1\n",
      "Precision: 0.7932461086908976\n",
      "Recall: 0.7972064991792043\n",
      "F1: 0.794953336318334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793246</td>\n",
       "      <td>0.797206</td>\n",
       "      <td>0.794953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        f1\n",
       "0   0.793246  0.797206  0.794953"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"BertScore por defecto a temperatura 1\")\n",
    "calcular_bertscore_defecto(df_llama_sin_rol_1, df_llama_con_rol_1)\n",
    "print (\"BertScore por defecto a temperatura 0.5\")\n",
    "calcular_bertscore_defecto(df_llama_sin_rol_0_5, df_llama_con_rol_0_5)\n",
    "print (\"BertScore por defecto a temperatura 0.1\")\n",
    "calcular_bertscore_defecto(df_llama_sin_rol_0_1, df_llama_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad653e75",
   "metadata": {},
   "source": [
    "### Bert utilizando modelo Bio_ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c81e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore con modelo Bio_ClinicalBERT a temperatura 1\n",
      "Precission: 0.7426342368125916\n",
      "Recall: 0.7288378477096558\n",
      "F1: 0.7354907393455505\n",
      "BertScore con modelo Bio_ClinicalBERT a temperatura 0.5\n",
      "Precission: 0.7294520139694214\n",
      "Recall: 0.7297423481941223\n",
      "F1: 0.7293215394020081\n",
      "BertScore con modelo Bio_ClinicalBERT a temperatura 0.1\n",
      "Precission: 0.723676323890686\n",
      "Recall: 0.7207764983177185\n",
      "F1: 0.7219652533531189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(0.7237)</td>\n",
       "      <td>tensor(0.7208)</td>\n",
       "      <td>tensor(0.7220)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision          recall              f1\n",
       "0  tensor(0.7237)  tensor(0.7208)  tensor(0.7220)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"BertScore con modelo Bio_ClinicalBERT a temperatura 1\")\n",
    "calcular_bertscore_bioclinical(df_llama_sin_rol_1, df_llama_con_rol_1)\n",
    "print (\"BertScore con modelo Bio_ClinicalBERT a temperatura 0.5\")\n",
    "calcular_bertscore_bioclinical(df_llama_sin_rol_0_5, df_llama_con_rol_0_5)\n",
    "print (\"BertScore con modelo Bio_ClinicalBERT a temperatura 0.1\")\n",
    "calcular_bertscore_bioclinical(df_llama_sin_rol_0_1, df_llama_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef331ae4",
   "metadata": {},
   "source": [
    "## Medidas de readabilidad y comprensión del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b771f70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas de readabilty y comprensión para sin rol a 1\n",
      "Flesch Reading Ease Scores: 35.73721710962494\n",
      "SMOG Index Scores: 13.092083281269657\n",
      "Dale-Chall Index Scores: 7.97569182076518\n",
      "Sentiment Polarity Scores: 0.0727435064935065\n",
      "Sentiment Subjectivity Scores: 0.37562229437229433\n",
      "Lexical Diversity Scores: 0.7285361261743131\n",
      "Lexical Richness Scores: 0.015097966041170913\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para con rol a 1\n",
      "Flesch Reading Ease Scores: 39.55900010851506\n",
      "SMOG Index Scores: 10.179524572218234\n",
      "Dale-Chall Index Scores: 6.11039722890901\n",
      "Sentiment Polarity Scores: -0.027253787878787888\n",
      "Sentiment Subjectivity Scores: 0.19066693722943723\n",
      "Lexical Diversity Scores: 0.7522334319075863\n",
      "Lexical Richness Scores: 0.015713019960498235\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para sin rol a 0.5\n",
      "Flesch Reading Ease Scores: 39.230504234887384\n",
      "SMOG Index Scores: 13.87000152930687\n",
      "Dale-Chall Index Scores: 8.387172513944526\n",
      "Sentiment Polarity Scores: 0.09628184910327767\n",
      "Sentiment Subjectivity Scores: 0.40797990105132964\n",
      "Lexical Diversity Scores: 0.7099723558338954\n",
      "Lexical Richness Scores: 0.01470271011134242\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para con rol a 0.5\n",
      "Flesch Reading Ease Scores: 51.78394989194525\n",
      "SMOG Index Scores: 8.07984458669917\n",
      "Dale-Chall Index Scores: 6.505649626560993\n",
      "Sentiment Polarity Scores: -0.0439318783068783\n",
      "Sentiment Subjectivity Scores: 0.19711640211640213\n",
      "Lexical Diversity Scores: 0.7822707749766573\n",
      "Lexical Richness Scores: 0.01755643525485833\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para sin rol a 0.1\n",
      "Flesch Reading Ease Scores: 40.72821886533294\n",
      "SMOG Index Scores: 11.92250093511792\n",
      "Dale-Chall Index Scores: 7.84166123482085\n",
      "Sentiment Polarity Scores: -0.007468253968253971\n",
      "Sentiment Subjectivity Scores: 0.2603253968253968\n",
      "Lexical Diversity Scores: 0.7558297489854503\n",
      "Lexical Richness Scores: 0.013890230927902151\n",
      "----------------------------------------------------\n",
      "Metricas de readabilty y comprensión para con rol a 0.1\n",
      "Flesch Reading Ease Scores: 56.3908148174264\n",
      "SMOG Index Scores: 9.460258327572426\n",
      "Dale-Chall Index Scores: 6.876006065718384\n",
      "Sentiment Polarity Scores: -0.020694444444444446\n",
      "Sentiment Subjectivity Scores: 0.24289562289562286\n",
      "Lexical Diversity Scores: 0.8218837305403847\n",
      "Lexical Richness Scores: 0.015099371138785378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>dale_chall_index</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>lexical_richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.390815</td>\n",
       "      <td>9.460258</td>\n",
       "      <td>6.876006</td>\n",
       "      <td>-0.020694</td>\n",
       "      <td>0.242896</td>\n",
       "      <td>0.821884</td>\n",
       "      <td>0.015099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flesch_reading_ease  smog_index  dale_chall_index  sentiment_polarity  \\\n",
       "0            56.390815    9.460258          6.876006           -0.020694   \n",
       "\n",
       "   sentiment_subjectivity  lexical_diversity  lexical_richness  \n",
       "0                0.242896           0.821884          0.015099  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Metricas de readabilty y comprensión para sin rol a 1\")\n",
    "calcular_metricas_comprension(df_llama_sin_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para con rol a 1\")\n",
    "calcular_metricas_comprension(df_llama_con_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para sin rol a 0.5\")\n",
    "calcular_metricas_comprension(df_llama_sin_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para con rol a 0.5\")\n",
    "calcular_metricas_comprension(df_llama_con_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para sin rol a 0.1\")\n",
    "calcular_metricas_comprension(df_llama_sin_rol_0_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Metricas de readabilty y comprensión para con rol a 0.1\")\n",
    "calcular_metricas_comprension(df_llama_con_rol_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9addc8a5",
   "metadata": {},
   "source": [
    "## Calcular longitud media de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44d83f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud textos y respuestas sin rol a 1\n",
      "Longitud de los textos: 1440.46\n",
      "Longitud de las respuestas: 95.52\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas con rol a 1\n",
      "Longitud de los textos: 1438.46\n",
      "Longitud de las respuestas: 80.43333333333334\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas sin rol a 0.5\n",
      "Longitud de los textos: 1438.46\n",
      "Longitud de las respuestas: 85.68666666666667\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas con rol a 0.5\n",
      "Longitud de los textos: 1438.46\n",
      "Longitud de las respuestas: 79.17333333333333\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas sin rol a 0.1\n",
      "Longitud de los textos: 1438.46\n",
      "Longitud de las respuestas: 87.4\n",
      "----------------------------------------------------\n",
      "Longitud textos y respuestas con rol a 0.1\n",
      "Longitud de los textos: 1438.46\n",
      "Longitud de las respuestas: 81.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitud_textos</th>\n",
       "      <th>longitud_respuestas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1438.46</td>\n",
       "      <td>81.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitud_textos  longitud_respuestas\n",
       "0          1438.46                 81.4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Longitud textos y respuestas sin rol a 1\")\n",
    "calcular_longitud_texto_y_respuesta(df_llama_sin_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas con rol a 1\")\n",
    "calcular_longitud_texto_y_respuesta(df_llama_con_rol_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas sin rol a 0.5\")\n",
    "calcular_longitud_texto_y_respuesta(df_llama_sin_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas con rol a 0.5\")\n",
    "calcular_longitud_texto_y_respuesta(df_llama_con_rol_0_5)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas sin rol a 0.1\")\n",
    "calcular_longitud_texto_y_respuesta(df_llama_sin_rol_0_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Longitud textos y respuestas con rol a 0.1\")\n",
    "calcular_longitud_texto_y_respuesta(df_llama_con_rol_0_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
